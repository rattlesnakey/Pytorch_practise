{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "#这个应该是要用的那个CNN，到时候改一下就可以，这个其实就是一个TDNN_layer\n",
    "#self.padlen = int(dilation * (context_size - 1) / 2)\n",
    "class TDNN(nn.Module):\n",
    "    def __init__(self, num_speakers):\n",
    "        super(TDNN,self).__init__()\n",
    "        self.TDNN1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 39, out_channels = 512, kernel_size = 5, padding = 1, dilation = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512, momentum=0.1, affine=True, track_running_stats = True),\n",
    "            nn.Dropout(p = 0.5)\n",
    "        )\n",
    "        self.TDNN2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 512, out_channels = 512, kernel_size = 3, padding = 2, dilation = 2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512, momentum=0.1, affine=True, track_running_stats = True),\n",
    "            nn.Dropout(p = 0.5)\n",
    "        )\n",
    "        self.TDNN3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 512, out_channels = 512, kernel_size = 3, padding = 3, dilation = 3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512, momentum=0.1, affine=True, track_running_stats = True),\n",
    "            nn.Dropout(p = 0.5)\n",
    "        )\n",
    "        self.TDNN4 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 512, out_channels = 512, kernel_size = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512, momentum=0.1, affine=True, track_running_stats = True),\n",
    "            nn.Dropout(p = 0.5)\n",
    "        )\n",
    "        self.TDNN5 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 512, out_channels = 1536, kernel_size = 3, padding = 3, dilation = 3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1536, momentum=0.1, affine=True, track_running_stats = True),\n",
    "            nn.Dropout(p = 0.5)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(2*1536,512)\n",
    "        self.bn_fc1 = nn.BatchNorm1d(512, momentum=0.1, affine=True, track_running_stats = True)\n",
    "        self.dropout_fc1 = nn.Dropout(p = 0.5)\n",
    "\n",
    "        self.fc2 = nn.Linear(512,64)\n",
    "        self.bn_fc2 = nn.BatchNorm1d(64, momentum=0.1, affine=True, track_running_stats = True)\n",
    "        self.dropout_fc2 = nn.Dropout(p = 0.5)\n",
    "        self.fc3 = nn.Linear(64,num_speakers)\n",
    "\n",
    "    def statis_pooling(self,x):\n",
    "        stats = torch.cat((x.mean(dim=2), x.std(dim=2)), dim=1)\n",
    "        return stats\n",
    "\n",
    "    def forward(self, x):#eps是噪声部分\n",
    "        x = self.TDNN1(x)\n",
    "        x = self.TDNN2(x)\n",
    "        x = self.TDNN3(x)\n",
    "        x = self.TDNN4(x)\n",
    "        x = self.TDNN5(x)\n",
    "\n",
    "#         if self.training:\n",
    "#             x = x + torch.randn(x.size()).cuda()*eps\n",
    "        stats = self.statis_pooling(x)\n",
    "        x = self.dropout_fc1(self.bn_fc1(F.relu(self.fc1(stats))))\n",
    "        x = self.dropout_fc2(self.bn_fc2(F.relu(self.fc2(x))))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def extract_x_vector(self, x):\n",
    "        x = self.TDNN1(x)\n",
    "        x = self.TDNN2(x)\n",
    "        x = self.TDNN3(x)\n",
    "        x = self.TDNN4(x)\n",
    "        x = self.TDNN5(x)\n",
    "        stats = self.statis_pooling(x)\n",
    "        xvec = self.fc1(stats)\n",
    "        return xvec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TDNN(43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(10, 39, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(x,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 43])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "x_vector = model.extract_x_vector(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 512])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TDNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, num_speakers, p_dropout):\n",
    "        super(TDNN, self).__init__()\n",
    "        self.tdnn1 = nn.Conv1d(in_channels = input_dim, out_channels = 512, kernel_size = 5, padding = 2 ,dilation = 1 )\n",
    "        self.bn_tdnn1 = nn.BatchNorm1d(512, momentum=0.1, affine=True)\n",
    "        self.dropout_tdnn1 = nn.Dropout(p=p_dropout)\n",
    "\n",
    "        self.tdnn2 = nn.Conv1d(in_channels=512, out_channels=512, kernel_size=3, padding = 2,dilation=2)\n",
    "        self.bn_tdnn2 = nn.BatchNorm1d(512, momentum=0.1, affine=True)\n",
    "        self.dropout_tdnn2 = nn.Dropout(p=p_dropout)\n",
    "\n",
    "        self.tdnn3 = nn.Conv1d(in_channels=512, out_channels=512,kernel_size=3, padding = 3,dilation=3)\n",
    "        self.bn_tdnn3 = nn.BatchNorm1d(512, momentum=0.1, affine=True)\n",
    "        self.dropout_tdnn3 = nn.Dropout(p=p_dropout)\n",
    "        \n",
    "        self.tdnn4 = nn.Conv1d(in_channels=512, out_channels=512,kernel_size=1)\n",
    "        self.bn_tdnn4 = nn.BatchNorm1d(512, momentum=0.1, affine=True)\n",
    "        self.dropout_tdnn4 = nn.Dropout(p=p_dropout)\n",
    "\n",
    "        self.tdnn5 = nn.Conv1d(in_channels=512, out_channels=1536,kernel_size=1)\n",
    "        self.bn_tdnn5 = nn.BatchNorm1d(1536, momentum=0.1, affine=True)\n",
    "        self.dropout_tdnn5 = nn.Dropout(p=p_dropout)\n",
    "\n",
    "        self.fc1 = nn.Linear(2*1536,512)\n",
    "        self.bn_fc1 = nn.BatchNorm1d(512, momentum=0.1, affine=True)\n",
    "        self.dropout_fc1 = nn.Dropout(p=p_dropout)\n",
    "\n",
    "        self.fc2 = nn.Linear(512,128)\n",
    "        self.bn_fc2 = nn.BatchNorm1d(128, momentum=0.1, affine=True)\n",
    "        self.dropout_fc2 = nn.Dropout(p=p_dropout)\n",
    "\n",
    "        self.fc3 = nn.Linear(128,num_speakers)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.dropout_tdnn1(self.bn_tdnn1(F.relu(self.tdnn1(x))))\n",
    "        print(x.shape)\n",
    "        x = self.dropout_tdnn2(self.bn_tdnn2(F.relu(self.tdnn2(x))))\n",
    "        print(x.shape)\n",
    "        x = self.dropout_tdnn3(self.bn_tdnn3(F.relu(self.tdnn3(x))))\n",
    "        print(x.shape)\n",
    "        x = self.dropout_tdnn4(self.bn_tdnn4(F.relu(self.tdnn4(x))))\n",
    "        print(x.shape)\n",
    "        x = self.dropout_tdnn5(self.bn_tdnn5(F.relu(self.tdnn5(x))))\n",
    "        print(x.shape)\n",
    "\n",
    "        stats = torch.cat((x.mean(dim=2), x.std(dim=2)), dim=1)\n",
    "        x = self.dropout_fc1(self.bn_fc1(F.relu(self.fc1(stats))))\n",
    "        x = self.dropout_fc2(self.bn_fc2(F.relu(self.fc2(x))))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def extract_x_vector(self, x):\n",
    "        x = self.dropout_tdnn1(self.bn_tdnn1(F.relu(self.tdnn1(x))))\n",
    "        x = self.dropout_tdnn2(self.bn_tdnn2(F.relu(self.tdnn2(x))))\n",
    "        x = self.dropout_tdnn3(self.bn_tdnn3(F.relu(self.tdnn3(x))))\n",
    "        x = self.dropout_tdnn4(self.bn_tdnn4(F.relu(self.tdnn4(x))))\n",
    "        x = self.dropout_tdnn5(self.bn_tdnn5(F.relu(self.tdnn5(x))))\n",
    "\n",
    "        stats = torch.cat((x.mean(dim=2), x.std(dim=2)), dim=1)\n",
    "        xv = self.bn_fc1(F.relu(self.fc1(stats)))\n",
    "        return xv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TDNN(39, 43, 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 512, 135])\n",
      "torch.Size([10, 512, 135])\n",
      "torch.Size([10, 512, 135])\n",
      "torch.Size([10, 512, 135])\n",
      "torch.Size([10, 1536, 135])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-5.0818e-01, -5.6307e-01, -4.1031e-01,  7.1857e-01,  4.1813e-01,\n",
       "          5.0056e-01, -2.6477e-01, -8.1584e-02, -2.6281e-01,  1.0420e+00,\n",
       "          3.2823e-01, -9.1143e-01, -3.8315e-01,  7.1892e-01,  5.0216e-01,\n",
       "         -4.0544e-02, -9.0196e-01,  1.8183e-01, -1.4102e-01, -3.6217e-01,\n",
       "         -5.1227e-01,  8.0957e-01, -3.6199e-01,  3.7434e-01, -5.4407e-01,\n",
       "          6.3408e-01,  9.8175e-01, -7.1631e-01, -4.2326e-01, -7.6716e-01,\n",
       "          1.2074e+00,  1.7428e-01,  4.4338e-01, -1.0573e+00,  1.1206e+00,\n",
       "          2.0939e-01,  7.2251e-01, -2.7699e-01, -5.8753e-01,  6.4379e-02,\n",
       "          2.2755e-01,  5.6865e-01, -1.2766e-01],\n",
       "        [-1.2177e+00,  1.6044e-02, -8.7840e-01, -3.3230e-01, -1.0604e+00,\n",
       "         -1.0430e+00, -5.1973e-02,  8.6193e-01,  7.8067e-01,  7.8111e-01,\n",
       "          2.0963e-01, -8.0671e-01,  3.8851e-01,  1.8397e-03, -3.1295e-01,\n",
       "         -2.8312e-01, -7.8557e-01, -1.6477e+00, -7.9928e-01,  5.1726e-01,\n",
       "         -2.8910e-01, -1.3274e+00,  2.1086e+00, -1.0051e+00, -1.3004e+00,\n",
       "          8.8089e-01, -1.1257e+00,  7.8591e-01, -1.7649e+00,  1.3897e-01,\n",
       "          6.4854e-01,  7.9092e-01,  5.4744e-01,  1.3098e+00,  3.3755e-01,\n",
       "         -3.8180e-01, -2.0966e+00,  5.5984e-01, -3.4716e-01, -7.0959e-01,\n",
       "         -3.0848e-01,  1.0036e-01,  9.6267e-01],\n",
       "        [ 7.2654e-01,  3.8444e-01,  4.0131e-02, -5.6190e-01,  2.6478e-01,\n",
       "         -1.5366e-01,  1.1416e+00, -3.0314e-01, -3.6940e-01, -7.1363e-01,\n",
       "         -3.7079e-01,  3.7904e-01,  1.9509e-01, -1.0122e+00,  5.7642e-01,\n",
       "         -1.2539e+00, -1.4026e-01,  8.7187e-01, -8.2102e-02, -9.0784e-01,\n",
       "          1.2456e+00, -1.1620e+00, -2.7189e-01, -1.9387e-02,  5.1050e-01,\n",
       "          3.0816e-01,  2.8972e-01, -9.6757e-01,  4.5738e-01, -4.0569e-01,\n",
       "         -4.3930e-01, -3.4488e-01, -7.2940e-01, -6.2890e-01, -1.1661e+00,\n",
       "         -1.5968e+00,  5.0098e-01,  3.2344e-01,  1.3438e+00, -7.6056e-01,\n",
       "         -5.7156e-02,  9.3800e-01, -8.7807e-01],\n",
       "        [ 3.2695e-01, -2.2849e-01, -6.9995e-01, -2.9879e-01, -2.5015e-01,\n",
       "          9.2415e-04,  4.7873e-01, -7.6948e-01,  7.4168e-01,  5.2130e-01,\n",
       "         -5.6628e-01,  3.7853e-01, -4.6041e-01,  9.2734e-01,  1.3726e-01,\n",
       "         -3.0288e-01,  1.0429e-02,  7.9358e-01, -4.7405e-01, -1.9051e-02,\n",
       "          3.1527e-01, -1.5042e+00, -6.8313e-01, -9.8622e-02,  1.1456e+00,\n",
       "         -2.6038e-01,  8.1785e-01, -3.2163e-01,  2.9587e-01,  1.9249e-01,\n",
       "         -1.0176e+00,  8.2517e-01, -2.9517e-01, -5.8946e-01, -4.5390e-01,\n",
       "         -8.0754e-01,  6.1388e-01, -4.9926e-01,  4.4177e-01,  3.9076e-01,\n",
       "          1.5430e-01,  1.1408e+00, -5.8321e-01],\n",
       "        [ 4.5581e-01, -7.4252e-01,  5.7042e-01, -2.5934e-01, -2.1775e-01,\n",
       "          9.3609e-01,  2.5983e-01,  3.7389e-01,  9.5982e-01,  6.7944e-01,\n",
       "          2.6978e-01,  2.0028e-01,  4.4745e-01, -4.8692e-01,  3.8654e-02,\n",
       "         -3.7054e-01,  1.8600e-01, -8.0811e-01, -3.6618e-01,  5.0145e-01,\n",
       "          3.4140e-01, -1.7713e-01,  3.4277e-01,  1.6875e+00,  4.2034e-02,\n",
       "         -9.1885e-02, -9.8797e-02, -7.1401e-01,  1.1689e+00,  1.1331e-01,\n",
       "         -3.1364e-01,  2.8134e-01, -4.5605e-01,  8.0296e-01,  9.3556e-01,\n",
       "         -2.3932e-01,  7.1804e-02, -7.8414e-01,  4.6571e-01,  4.2716e-01,\n",
       "          3.7786e-02, -6.3249e-01,  2.5085e-01],\n",
       "        [ 6.1851e-02,  1.5055e+00, -6.6213e-01, -3.2281e-01, -9.9895e-01,\n",
       "          8.5866e-01,  2.6413e-01,  1.1795e+00, -2.2759e-01, -8.0525e-01,\n",
       "          2.5479e-01, -5.2187e-01,  3.9499e-01, -2.8393e-01,  7.8168e-01,\n",
       "          4.7062e-01, -2.5640e-01,  4.0729e-01,  6.8262e-01, -4.3118e-01,\n",
       "         -2.2304e-01, -5.8055e-01,  1.3875e+00,  5.9261e-01, -1.2179e+00,\n",
       "          1.5316e-01,  2.9232e-01,  1.3355e-01, -8.8294e-01,  6.6236e-01,\n",
       "          7.9902e-01,  3.5865e-01, -1.0296e+00, -8.0106e-01,  5.3849e-01,\n",
       "          4.2457e-01,  4.1832e-01,  8.0062e-01, -1.2745e+00,  1.3603e+00,\n",
       "         -8.1700e-01,  6.0733e-01, -9.7452e-01],\n",
       "        [-7.6086e-02,  7.2896e-01,  3.3904e-01,  3.5141e-02, -6.4500e-01,\n",
       "          8.5265e-01, -3.1685e-02, -2.6892e-01, -4.8786e-01,  5.3906e-01,\n",
       "         -3.7949e-02, -4.6744e-01,  2.5454e-01,  3.1018e-01,  7.5355e-02,\n",
       "         -2.0580e-01,  7.9243e-01, -4.8378e-02,  8.3685e-01,  1.5228e-01,\n",
       "         -7.4028e-01,  1.2824e+00, -4.8881e-01,  1.8444e+00,  2.1225e-01,\n",
       "          3.6190e-03,  4.8290e-02,  6.0820e-01,  9.7191e-01, -1.2127e-01,\n",
       "         -3.4054e-01,  4.4094e-02,  1.0749e+00,  2.9050e-02, -8.8487e-01,\n",
       "         -5.7104e-01, -6.9476e-01, -8.3791e-02, -6.1975e-01, -4.9998e-01,\n",
       "          7.7260e-01, -2.5772e-01, -5.1059e-01],\n",
       "        [-2.8009e-01,  7.3370e-01, -9.8005e-01,  7.5614e-01,  1.2962e-01,\n",
       "         -1.5971e+00, -4.4912e-01,  7.6550e-01, -6.7512e-01, -9.2152e-01,\n",
       "         -1.1166e+00,  5.2220e-01, -5.4453e-01, -2.5677e-01, -3.8354e-01,\n",
       "          4.1484e-01, -1.1831e-01,  4.3862e-01, -3.8559e-01, -2.1721e-01,\n",
       "         -3.5671e-01, -3.5309e-02, -6.3893e-01, -1.3406e+00,  5.3446e-01,\n",
       "         -4.8294e-01, -2.0926e-02,  4.5394e-01, -1.8941e-01, -2.9668e-01,\n",
       "          4.4627e-01, -9.2151e-01,  7.6248e-01,  3.7374e-01,  1.1916e+00,\n",
       "         -2.6552e-01,  2.4608e-01,  7.9892e-01, -4.1743e-01, -3.5258e-01,\n",
       "         -6.5574e-01, -7.9295e-01, -1.1965e+00],\n",
       "        [ 2.4365e-01, -6.6084e-01, -4.0837e-01,  9.0038e-01, -2.1360e-01,\n",
       "         -5.7868e-01, -3.9478e-01,  1.6142e-01,  2.3323e-01,  2.0712e-02,\n",
       "          1.2654e+00,  8.0613e-02, -7.8376e-01,  6.4022e-01,  6.7427e-02,\n",
       "          1.0358e+00, -1.6150e+00, -5.6190e-02, -2.6042e-01,  1.8244e+00,\n",
       "          4.4105e-01,  5.5751e-01, -8.2603e-01, -9.2179e-01, -1.0892e+00,\n",
       "          2.9790e-01, -8.4269e-01,  4.3652e-01,  4.2072e-01,  6.3664e-02,\n",
       "          8.7959e-01, -8.6558e-01, -4.5638e-01, -2.5744e-01, -6.4900e-01,\n",
       "          3.4503e-01, -6.8482e-02, -4.3726e-01,  1.1517e+00,  2.3639e-01,\n",
       "          4.7872e-01, -6.5984e-01,  4.3411e-01],\n",
       "        [ 8.4494e-01,  3.5939e-01, -1.3736e-01,  6.5581e-01, -7.3888e-01,\n",
       "          4.4056e-01, -2.8600e-01,  7.4885e-01,  7.9947e-01, -2.7449e-01,\n",
       "         -2.3152e-01, -3.6319e-01,  3.5168e-02,  6.7349e-01, -4.0797e-01,\n",
       "          8.3525e-01, -1.5196e-01, -1.0190e+00,  2.8706e-01,  9.9706e-01,\n",
       "         -5.9655e-01,  4.2469e-01,  3.6392e-01,  6.6116e-01,  3.2292e-01,\n",
       "         -1.3398e-01, -1.0669e+00, -3.9741e-01,  1.4132e-01,  6.8713e-01,\n",
       "         -7.2410e-01, -2.7164e-01,  7.6914e-02, -4.6082e-01, -1.8678e-02,\n",
       "         -5.5925e-02, -5.1826e-01,  8.5065e-01,  1.0814e-01,  4.2226e-01,\n",
       "         -2.0239e-01, -3.3683e-02,  8.3760e-01]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_feature = torch.rand(10,39,135)\n",
    "model(input_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1,2]\n",
    "max(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
