{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "occur_thres=20\n",
    "ambiguity_thres=0.97\n",
    "bos=['<bos-1>','<bos-2>']\n",
    "eos=['<eos-1>','<eos-2>']\n",
    "bop=['<bop-1>','<bop-2>']\n",
    "eop=['<eop-1>','<eop-2>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(train_data):\n",
    "    word_pos_counter={}\n",
    "    pos_vocab=set()\n",
    "    with open(train_data) as fr:\n",
    "        for line in fr:\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            word,pos_tag=line.strip().split('\\t')\n",
    "            if word not in word_pos_counter:\n",
    "                word_pos_counter[word]={}\n",
    "            if pos_tag not in word_pos_counter[word]:\n",
    "                word_pos_counter[word][pos_tag]=0\n",
    "            word_pos_counter[word][pos_tag]+=1\n",
    "            \n",
    "            if pos_tag not in pos_vocab:\n",
    "                pos_vocab.add(pos_tag)\n",
    "    \n",
    "    single_pos_dict={}\n",
    "    for word,tag_freqs in word_pos_counter.items():\n",
    "        tag,mode=max(tag_freqs.items(),key=lambda item:item[1])\n",
    "        n=sum(tag_freqs.values())\n",
    "        if n>=occur_thres and (float(mode)/n) >= ambiguity_thres:\n",
    "            single_pos_dict[word] = tag\n",
    "            \n",
    "    return single_pos_dict,pos_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_pos_dict,pos_vocab=get_vocab('./train.pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    sentence=[]\n",
    "    pos_tag=[]\n",
    "    line_sent=[]\n",
    "    line_pos=[]\n",
    "    for sent in open(path):\n",
    "        if not sent.strip():\n",
    "            sentence.append(line_sent)\n",
    "            pos_tag.append(line_pos)\n",
    "            line_sent=[]\n",
    "            line_pos=[]\n",
    "            continue\n",
    "        \n",
    "        w,p=sent.strip().split('\\t')\n",
    "        line_sent.append(w)\n",
    "        line_pos.append(p)\n",
    "        \n",
    "    return sentence,pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 39830\n",
      "dev size: 1700\n",
      "test size: 2416\n"
     ]
    }
   ],
   "source": [
    "train_sent,train_pos=read_data('./train.pos')\n",
    "print('train size:',len(train_sent))\n",
    "dev_sent,dev_pos=read_data('./dev.pos')\n",
    "print('dev size:',len(dev_sent))\n",
    "test_sent,test_pos=read_data('./test.pos')\n",
    "print('test size:',len(test_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(i, word, context, prev, prev2):\n",
    "    '''Map tokens into a feature representation, implemented as a\n",
    "    {hashable: float} dict. If the features change, a new model must be\n",
    "    trained.\n",
    "    '''\n",
    "    def add(name, *args):\n",
    "        features[' '.join((name,) + tuple(args))] += 1\n",
    "\n",
    "    i += len(bos)\n",
    "    features = defaultdict(int)\n",
    "    # It's useful to have a constant feature, which acts sort of like a prior\n",
    "    add('bias')\n",
    "    add('i suffix', word[-3:])\n",
    "    add('i pref1', word[0])\n",
    "    add('i-1 tag', prev)\n",
    "    add('i-2 tag', prev2)\n",
    "    add('i tag+i-2 tag', prev, prev2)\n",
    "    add('i word', context[i])\n",
    "    add('i-1 tag+i word', prev, context[i])\n",
    "    add('i-1 word', context[i-1])\n",
    "    add('i-1 suffix', context[i-1][-3:])\n",
    "    add('i-2 word', context[i-2])\n",
    "    add('i+1 word', context[i+1])\n",
    "    add('i+1 suffix', context[i+1][-3:])\n",
    "    add('i+2 word', context[i+2])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(word):\n",
    "    '''Normalization used in pre-processing.\n",
    "    - All words are lower cased\n",
    "    - Digits in the range 1800-2100 are represented as !YEAR;\n",
    "    - Other digits are represented as !DIGITS\n",
    "    :rtype: str\n",
    "    '''\n",
    "    if '-' in word and word[0] != '-':\n",
    "        return '!HYPHEN'\n",
    "    elif word.isdigit() and len(word) == 4:\n",
    "        return '!YEAR'\n",
    "    elif word[0].isdigit():\n",
    "        return '!DIGITS'\n",
    "    else:\n",
    "        return word.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(sent_data,pos_data):\n",
    "    words=[]\n",
    "    feats=[]\n",
    "    trgs=[]\n",
    "    assert len(sent_data)==len(pos_data)\n",
    "    for sent_seq,pos_seq in zip(sent_data,pos_data):\n",
    "        sent_seq=bos+[normalize(word) for word in sent_seq]+eos\n",
    "        pos_seq=bop+pos_seq+eop\n",
    "        for idx,(word,pos)in enumerate(zip(sent_seq[2:-2],pos_seq[2:-2])):\n",
    "            words.append(word)\n",
    "            trgs.append(pos)\n",
    "            feats.append(get_features(idx,word,sent_seq,pos_seq[idx-1],pos_seq[idx-2]))\n",
    "    return words,feats,trgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_words,train_feats,train_trgs=process_data(train_sent,train_pos)\n",
    "dev_words,dev_feats,dev_trgs=process_data(dev_sent,dev_pos)\n",
    "test_words,test_feats,test_trgs=process_data(test_sent,test_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | num updates 79682 (8.3875%) | train cor 91.6125% |dev cor 93.4566%\n"
     ]
    }
   ],
   "source": [
    "from perceptron import AveragedPerceptron\n",
    "import copy\n",
    "model=AveragedPerceptron()\n",
    "model.classes=pos_vocab\n",
    "\n",
    "#for epoch in range(1,21):\n",
    "for epoch in range(1,2):\n",
    "    num_update=0\n",
    "    train_cor=0\n",
    "    for idx,(feats,trg)in enumerate(zip(train_feats,train_trgs)):\n",
    "        guess=model.predict(feats)\n",
    "        if guess != trg:\n",
    "            num_update+=1\n",
    "            model.update(trg,guess,feats)\n",
    "        else:\n",
    "            train_cor+=1\n",
    "    #model.average_weights()\n",
    "    #model.save('./normal-{:03d}.pkl'.format(epoch))\n",
    "    \n",
    "    dev_cor=0\n",
    "    for idx,(feats,trg)in enumerate(zip(dev_feats,dev_trgs)):\n",
    "        guess=model.predict(feats)\n",
    "        if guess == trg:\n",
    "            dev_cor+=1\n",
    "    print(\"Epoch {} | num updates {} ({:.4f}%) | train cor {:.4f}% |dev cor {:.4f}%\".format(\n",
    "        epoch,num_update,num_update/len(train_feats) *100,train_cor/len(train_feats) *100,dev_cor/len(dev_feats) *100))\n",
    "model.average_weights() \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-54d7259707a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model/plus-weighted.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\perceptron.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mclas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m                 \u001b[0mparam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m                 \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_totals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m                 \u001b[0mtotal\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tstamps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[0maveraged\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: write() argument must be str, not bytes"
     ]
    }
   ],
   "source": [
    "model.save('model/plus-weighted.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-d2c0983c4402>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./model/normal-weighted.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_cor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_feats\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_trgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mguess\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mguess\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtrg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\perceptron.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;34m'''Load the pickled model weights.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    }
   ],
   "source": [
    "model.load('./model/normal-weighted.pkl')\n",
    "test_cor=0\n",
    "for idx,(feats,trg)in enumerate(zip(test_feats,test_trgs)):\n",
    "    guess=model.predict(feats)\n",
    "    if guess == trg:\n",
    "        test_cor+=1\n",
    "print('Normal Test ACC {}%'.format(test_cor/len(test_feat)))\n",
    "\n",
    "model.load('./plus-weighted.pkl')\n",
    "test_cor=0\n",
    "for idx,(word,feats,trg)in enumerate(zip(test_words,test_feats,test_trgs)):\n",
    "    if word in single_pos_dict:\n",
    "        guess=single_pos_dict[word]\n",
    "    else:\n",
    "        guess=model.predict(feats)\n",
    "    if guess == trg:\n",
    "        test_cor+=1\n",
    "print('Plus Test ACC {}%'.format(test_cor/len(test_feat)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A(object):\n",
    "    def __init__(self,name):\n",
    "        self.name=name\n",
    "    def print_(self):\n",
    "        print(os.path.dirname(__file__))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=A(\"A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-fa5861687a5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-9cdecea22db0>\u001b[0m in \u001b[0;36mprint_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mprint_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "a.print_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
