{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "painful-composition",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "focal-essay",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "random-floor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import utils as nn_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "original-reverse",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "elect-newspaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 3\n",
    "hidden_size = 2\n",
    "n_layers = 1\n",
    "tensor_in = torch.FloatTensor([[1,2,3],[1,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "deluxe-brighton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "broad-consumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_in = tensor_in.resize_(2,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "olive-hebrew",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fixed-timothy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.],\n",
       "         [2.],\n",
       "         [3.]],\n",
       "\n",
       "        [[1.],\n",
       "         [0.],\n",
       "         [0.]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "authentic-vector",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = [3,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "freelance-timeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "pack = nn_utils.rnn.pack_padded_sequence(tensor_in, seq_len, batch_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "native-effort",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pack.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-mechanics",
   "metadata": {},
   "source": [
    "* [参考链接](https://zhuanlan.zhihu.com/p/161972223)\n",
    "* PackedSequence对象里面的batch_sizes是每个时间步骤对应的batch大小\n",
    "* sorted_indices就是对输入lengths排序后的索引(也就是说它会自动排好序)\n",
    "* unsorted_indices 是用来将排序数据恢复到原始顺序的索引\n",
    "* 在pack_padded_sequence中，enforce_sorted默认设置为True，也就是说输入的batch数据要事先按照长度排序，才能输入，实际上，更简单的方式是，将其设置为False，从上面的代码中也可以看出，Pytorch会自动给我们做排序。\n",
    "* 也就是说enforce_sorted设置为False的话，pack_padded_sequence方法就会自动帮我们排好序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "imposed-counter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[1.],\n",
       "        [1.],\n",
       "        [2.],\n",
       "        [3.]]), batch_sizes=tensor([2, 1, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "mature-earthquake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1.],\n",
       "          [2.],\n",
       "          [3.]],\n",
       " \n",
       "         [[1.],\n",
       "          [0.],\n",
       "          [0.]]]),\n",
       " tensor([3, 1]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_utils.rnn.pad_packed_sequence(pack, batch_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-violation",
   "metadata": {},
   "source": [
    "#### 现在这个是没有按照长度排好序的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "respected-intranet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_tensor shape：batch_size=2,time_step=3,dim=1\n",
    "input_tensor = torch.FloatTensor([[4, 0, 0], [5, 6, 0]]).resize_(2, 3, 1)\n",
    "seq_lens = torch.IntTensor([1, 2])\n",
    "x_packed = nn_utils.rnn.pack_padded_sequence(input_tensor, seq_lens, batch_first=True, enforce_sorted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "available-express",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[5.],\n",
       "        [4.],\n",
       "        [6.]]), batch_sizes=tensor([2, 1]), sorted_indices=tensor([1, 0]), unsorted_indices=tensor([1, 0]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_packed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-latex",
   "metadata": {},
   "source": [
    "* 返回的data里面的部分是每个time_step依次输出来的，也就我先输出第一样本的第一个time_step的值，再输出第二个样本的第一个time_step的值，直到把所有的样本的第一个time_step的值都输出来以后才去输出第二个time_step的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "angry-bookmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "olive-throat",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2,3, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naval-metro",
   "metadata": {},
   "source": [
    "* dim的是哪个维度，哪个维度加起来的和就是1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cognitive-purpose",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4710, 0.9405],\n",
       "         [0.4627, 0.0383],\n",
       "         [0.0664, 0.0212]],\n",
       "\n",
       "        [[0.2669, 0.2945],\n",
       "         [0.6290, 0.4887],\n",
       "         [0.1041, 0.2169]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(x, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-matthew",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
