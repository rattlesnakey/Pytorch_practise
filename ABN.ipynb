{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.1233,  0.1309,  0.2814, -1.9544, -1.2139,  0.9455],\n",
      "         [ 2.7893, -0.2317, -1.5156,  1.2039, -1.2037,  0.9130],\n",
      "         [ 1.2137,  0.6958, -0.4921, -0.8276,  0.8377,  0.9562],\n",
      "         [-1.5076,  0.6363,  0.5928, -0.6300,  0.0240,  1.9158],\n",
      "         [-0.5199,  0.1634,  1.4953, -0.4837,  0.2691, -0.7630]],\n",
      "\n",
      "        [[ 0.1926, -0.1499,  1.5808,  0.2936,  0.4000, -0.7620],\n",
      "         [-0.0719,  0.3883, -0.1320, -0.8559, -0.8921, -1.5119],\n",
      "         [-0.6167,  0.0750, -0.8566, -0.0536,  1.6675,  0.4145],\n",
      "         [ 0.2672, -0.5273, -0.6057, -0.6942,  0.3763, -0.1747],\n",
      "         [-0.8692, -1.4416,  0.7252,  0.4823,  0.4696,  0.5063]],\n",
      "\n",
      "        [[-0.5577,  0.0569,  0.0959,  0.2419, -0.4015, -1.3604],\n",
      "         [ 0.6920,  1.3198,  1.4232,  0.3770, -1.3151, -0.8023],\n",
      "         [-0.2655,  0.6422,  0.9520,  0.9185,  0.7974, -0.9940],\n",
      "         [-0.1103, -0.6113, -0.5758, -0.8179,  1.3566,  2.2937],\n",
      "         [ 0.1024, -0.5505,  0.2461, -0.4399,  0.5919, -0.7221]]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "def mean_features(x):\n",
    "    out = x.mean(0)\n",
    "    while out.dim() > 1:\n",
    "        out = out.mean(1)\n",
    "    return out\n",
    "\n",
    "def fowardbn(x, gam, beta, ):\n",
    "    momentum = 0.1\n",
    "    eps = 1e-05\n",
    "    running_mean = 0\n",
    "    running_var = 1\n",
    "    cur_mean = mean_features(x)\n",
    "    running_mean = (1 - momentum) * running_mean + momentum * cur_mean\n",
    "    running_var = (1 - momentum) * running_var + momentum * cur_mean\n",
    "    mean = cur_mean\n",
    "    cur_var = F.relu(mean_features(x**2) - cur_mean**2)\n",
    "    var = cur_var\n",
    "    x_hat = (x.view(-1,x.shape[1]) - cur_mean) / torch.sqrt(cur_var + eps)\n",
    "    print(gam.shape)\n",
    "    print(beta.shape)\n",
    "    out = gam * x_hat + beta\n",
    "    cache = (x, gam, beta, x_hat, mean, var, eps)\n",
    "    return out.view(x.shape), cache\n",
    "\n",
    "model2 = nn.BatchNorm1d(5)\n",
    "input1 = torch.randn(3,5,6, requires_grad=True)\n",
    "print(input1)\n",
    "input2 = input1.clone().detach().requires_grad_()\n",
    "y = model2(input1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 6])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5])\n",
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "out, cache = fowardbn(input2, torch.ones(5), torch.zeros(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 6])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsnooper import snoop\n",
    "class ABN(nn.Module):\n",
    "    def __init__(self,in_channels, out_channels):\n",
    "        super(ABN,self).__init__()\n",
    "        self.W_e = nn.Conv1d(in_channels, out_channels, 1, bias = True)\n",
    "        self.linear_transform1 = nn.Linear(135,in_channels)\n",
    "        self.linear_transform2 = nn.Linear(135,in_channels)\n",
    "    \n",
    "    def mean_features(self,x):\n",
    "        out = x.mean(0)\n",
    "        while out.dim() > 1:\n",
    "            out = out.mean(1)\n",
    "        return out\n",
    "    @snoop()\n",
    "    def forward(self, x):\n",
    "        momentum, eps,running_mean,running_var = 0.1, 1e-05, 0, 1\n",
    "        mean = mean_features(x)\n",
    "        running_mean = (1 - momentum) * running_mean + momentum * mean\n",
    "        running_var = (1 - momentum) * running_var + momentum * mean\n",
    "        var = F.relu(mean_features(x**2) - mean**2)\n",
    "        x_hat = (x.view(-1,x.shape[1]) - mean) / torch.sqrt(var + eps)\n",
    "        e_t = torch.tanh(self.W_e(x))\n",
    "        exp_mean_e_t = torch.exp(torch.mean(e_t,dim  = 2))\n",
    "        a_t = exp_mean_e_t/torch.sum(exp_mean_e_t,dim = 1).unsqueeze(1).expand(-1,e_t.shape[1])\n",
    "        a_t = a_t.unsqueeze(2).expand(-1,-1,e_t.shape[2])\n",
    "        C_abn = torch.sum(a_t * e_t, dim = 1)\n",
    "        gamma = self.linear_transform1(C_abn).mean(0)\n",
    "        beta = self.linear_transform2(C_abn).mean(0)\n",
    "        out = gamma * x_hat + beta\n",
    "        out = out.view(x.shape)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.rand(10,39,135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ABN(39,39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Source path:... <ipython-input-17-c886609fcd5f>\n",
      "Starting var:.. self = ABN(  (W_e): Conv1d(39, 39, kernel_size=(1,), st...ear(in_features=135, out_features=39, bias=True))\n",
      "Starting var:.. x = tensor<(10, 39, 135), float32, cpu>\n",
      "15:47:26.051538 call        15     def forward(self, x):\n",
      "15:47:26.063506 line        16         momentum, eps,running_mean,running_var = 0.1, 1e-05, 0, 1\n",
      "New var:....... momentum = 0.1\n",
      "New var:....... eps = 1e-05\n",
      "New var:....... running_mean = 0\n",
      "New var:....... running_var = 1\n",
      "15:47:26.065501 line        17         mean = mean_features(x)\n",
      "New var:....... mean = tensor<(39,), float32, cpu>\n",
      "15:47:26.067494 line        18         running_mean = (1 - momentum) * running_mean + momentum * mean\n",
      "Modified var:.. running_mean = tensor<(39,), float32, cpu>\n",
      "15:47:26.072485 line        19         running_var = (1 - momentum) * running_var + momentum * mean\n",
      "Modified var:.. running_var = tensor<(39,), float32, cpu>\n",
      "15:47:26.077477 line        20         var = F.relu(mean_features(x**2) - mean**2)\n",
      "New var:....... var = tensor<(39,), float32, cpu>\n",
      "15:47:26.080461 line        21         x_hat = (x.view(-1,x.shape[1]) - mean) / torch.sqrt(var + eps)\n",
      "New var:....... x_hat = tensor<(1350, 39), float32, cpu>\n",
      "15:47:26.082455 line        22         e_t = torch.tanh(self.W_e(x))\n",
      "New var:....... e_t = tensor<(10, 39, 135), float32, cpu, grad>\n",
      "15:47:26.100408 line        23         exp_mean_e_t = torch.exp(torch.mean(e_t,dim  = 2))\n",
      "New var:....... exp_mean_e_t = tensor<(10, 39), float32, cpu, grad>\n",
      "15:47:26.110385 line        24         a_t = exp_mean_e_t/torch.sum(exp_mean_e_t,dim = 1).unsqueeze(1).expand(-1,e_t.shape[1])\n",
      "New var:....... a_t = tensor<(10, 39), float32, cpu, grad>\n",
      "15:47:26.114369 line        25         a_t = a_t.unsqueeze(2).expand(-1,-1,e_t.shape[2])\n",
      "Modified var:.. a_t = tensor<(10, 39, 135), float32, cpu, grad>\n",
      "15:47:26.118358 line        26         C_abn = torch.sum(a_t * e_t, dim = 1)\n",
      "New var:....... C_abn = tensor<(10, 135), float32, cpu, grad>\n",
      "15:47:26.123346 line        27         gamma = self.linear_transform1(C_abn).mean(0)\n",
      "New var:....... gamma = tensor<(39,), float32, cpu, grad>\n",
      "15:47:26.130327 line        28         beta = self.linear_transform2(C_abn).mean(0)\n",
      "New var:....... beta = tensor<(39,), float32, cpu, grad>\n",
      "15:47:26.136312 line        29         out = gamma * x_hat + beta\n",
      "New var:....... out = tensor<(1350, 39), float32, cpu, grad>\n",
      "15:47:26.145288 line        30         out = out.view(x.shape)\n",
      "Modified var:.. out = tensor<(10, 39, 135), float32, cpu, grad>\n",
      "15:47:26.151272 line        31         return out\n",
      "15:47:26.160260 return      31         return out\n",
      "Return value:.. tensor<(10, 39, 135), float32, cpu, grad>\n",
      "Elapsed time: 00:00:00.115691\n"
     ]
    }
   ],
   "source": [
    "z = model(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 39, 135])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.rand(10,135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([135])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.mean(dim = 0 ).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ABN(nn.Module):\n",
    "    def __init__(self,in_channels):\n",
    "        super(ABN,self).__init__()\n",
    "        self.W_e = nn.Conv1d(in_channels, in_channels, 1, bias = True)\n",
    "        self.linear_transform1 = nn.Linear(in_channels,in_channels,bias = True)\n",
    "        self.linear_transform2 = nn.Linear(in_channels,in_channels,bias = True)\n",
    "    \n",
    "    def mean_features(self,x):\n",
    "        out = x.mean(0)\n",
    "        while out.dim() > 1:\n",
    "            out = out.mean(1)\n",
    "        return out\n",
    "    @snoop()\n",
    "    def forward(self, x):\n",
    "        momentum, eps,running_mean,running_var = 0.1, 1e-05, 0, 1\n",
    "        mean = self.mean_features(x).unsqueeze(0).unsqueeze(2).expand(x.shape[0],-1,x.shape[2])\n",
    "        running_mean = (1 - momentum) * running_mean + momentum * mean# (39,)\n",
    "        running_var = (1 - momentum) * running_var + momentum * mean# (39,)\n",
    "        var = (F.relu(mean**2) - mean**2)\n",
    "        x_hat = (x - mean) / torch.sqrt(var + eps)\n",
    "        e_t = torch.tanh(self.W_e(x))\n",
    "        exp_mean_e_t = torch.exp(torch.mean(e_t,dim  = 1))\n",
    "        a_t = exp_mean_e_t/torch.sum(exp_mean_e_t,dim = 1).unsqueeze(1).expand(-1,exp_mean_e_t.shape[1])\n",
    "        a_t = a_t.unsqueeze(1).expand(-1,e_t.shape[1],-1)\n",
    "        C_abn = torch.sum(a_t * e_t, dim = 2)\n",
    "        gamma = self.linear_transform1(C_abn).unsqueeze(2).expand(-1,-1,x.shape[2])\n",
    "        beta = self.linear_transform2(C_abn).unsqueeze(2).expand(-1,-1,x.shape[2])\n",
    "        out = gamma * x_hat + beta\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ABN(39,135)\n",
    "x = torch.rand(41,39,135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Source path:... <ipython-input-58-61d4016bf5a5>\n",
      "Starting var:.. self = ABN(  (W_e): Conv1d(39, 39, kernel_size=(1,), st...near(in_features=39, out_features=39, bias=True))\n",
      "Starting var:.. x = tensor<(41, 39, 135), float32, cpu>\n",
      "17:08:25.703611 call        15     def forward(self, x):\n",
      "17:08:25.710592 line        16         momentum, eps,running_mean,running_var = 0.1, 1e-05, 0, 1\n",
      "New var:....... momentum = 0.1\n",
      "New var:....... eps = 1e-05\n",
      "New var:....... running_mean = 0\n",
      "New var:....... running_var = 1\n",
      "17:08:25.712587 line        17         mean = self.mean_features(x).unsqueeze(0).unsqueeze(2).expand(x.shape[0],-1,x.shape[2])\n",
      "New var:....... mean = tensor<(41, 39, 135), float32, cpu>\n",
      "17:08:25.715579 line        18         running_mean = (1 - momentum) * running_mean + momentum * mean# (39,)\n",
      "Modified var:.. running_mean = tensor<(41, 39, 135), float32, cpu>\n",
      "17:08:25.721563 line        19         running_var = (1 - momentum) * running_var + momentum * mean# (39,)\n",
      "Modified var:.. running_var = tensor<(41, 39, 135), float32, cpu>\n",
      "17:08:25.727546 line        20         var = (F.relu(mean**2) - mean**2)\n",
      "New var:....... var = tensor<(41, 39, 135), float32, cpu>\n",
      "17:08:25.736522 line        21         x_hat = (x - mean) / torch.sqrt(var + eps)\n",
      "New var:....... x_hat = tensor<(41, 39, 135), float32, cpu>\n",
      "17:08:25.744501 line        22         e_t = torch.tanh(self.W_e(x))\n",
      "New var:....... e_t = tensor<(41, 39, 135), float32, cpu, grad>\n",
      "17:08:25.758469 line        23         exp_mean_e_t = torch.exp(torch.mean(e_t,dim  = 1))\n",
      "New var:....... exp_mean_e_t = tensor<(41, 135), float32, cpu, grad>\n",
      "17:08:25.772427 line        24         a_t = exp_mean_e_t/torch.sum(exp_mean_e_t,dim = 1).unsqueeze(1).expand(-1,exp_mean_e_t.shape[1])\n",
      "New var:....... a_t = tensor<(41, 135), float32, cpu, grad>\n",
      "17:08:25.787386 line        25         a_t = a_t.unsqueeze(1).expand(-1,e_t.shape[1],-1)\n",
      "Modified var:.. a_t = tensor<(41, 39, 135), float32, cpu, grad>\n",
      "17:08:25.807334 line        26         C_abn = torch.sum(a_t * e_t, dim = 2)\n",
      "New var:....... C_abn = tensor<(41, 39), float32, cpu, grad>\n",
      "17:08:25.824288 line        27         gamma = self.linear_transform1(C_abn).unsqueeze(2).expand(-1,-1,x.shape[2])\n",
      "New var:....... gamma = tensor<(41, 39, 135), float32, cpu, grad>\n",
      "17:08:25.840245 line        28         beta = self.linear_transform2(C_abn).unsqueeze(2).expand(-1,-1,x.shape[2])\n",
      "New var:....... beta = tensor<(41, 39, 135), float32, cpu, grad>\n",
      "17:08:25.856202 line        29         out = gamma * x_hat + beta\n",
      "New var:....... out = tensor<(41, 39, 135), float32, cpu, grad>\n",
      "17:08:25.874155 line        30         return out\n",
      "17:08:25.895098 return      30         return out\n",
      "Return value:.. tensor<(41, 39, 135), float32, cpu, grad>\n",
      "Elapsed time: 00:00:00.213430\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([41, 39, 135])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
