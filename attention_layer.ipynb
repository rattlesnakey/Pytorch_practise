{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#self-attention \n",
    "class SA(torch.nn.Module):\n",
    "    ''' Self Attention 自注意力 / Scaled Dot-Product Attention 缩放点积注意力\n",
    "\n",
    "        Vaswani A , Shazeer N , Parmar N , et al. Attention Is All You Need[J]. NIST, 2017.\n",
    "    '''\n",
    "    def __init__(self, ndim, kdim, vdim):\n",
    "        '''\n",
    "        ndim(int): input dimension\n",
    "        kdim(int): K dimension == Q dimension\n",
    "        vdim(int): V dimension\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.q1x1 = torch.nn.Conv1d(in_channels=ndim, out_channels=kdim, kernel_size=1)\n",
    "        self.k1x1 = torch.nn.Conv1d(in_channels=ndim, out_channels=kdim, kernel_size=1)\n",
    "        self.v1x1 = torch.nn.Conv1d(in_channels=ndim, out_channels=vdim, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x(float): shape [B, ndim, T]\n",
    "        '''\n",
    "        q = self.q1x1(x) # [B, qdim, Tq=T]\n",
    "        k = self.k1x1(x) # [B, kdim, Tk=T]\n",
    "        v = self.v1x1(x) # [B, vdim, Tv=T]\n",
    "        o = torch.matmul(k.permute(0,2,1), q).softmax(1) # [B, Tk, Tq]\n",
    "        o = torch.matmul(v, o)  # [B, kdim, Tq], kernel_size = 1所以Time是不变的,\n",
    "\n",
    "        return o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(10,39,110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 39, 110])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torch.nn.Conv1d(in_channels = 39, out_channels = 512, kernel_size = 1)\n",
    "k = torch.nn.Conv1d(in_channels = 39, out_channels = 512, kernel_size = 1)\n",
    "v = torch.nn.Conv1d(in_channels = 39, out_channels = 256, kernel_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 512, 110])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_matrix = q(x)\n",
    "q_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 512, 110])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_matrix = k(x)\n",
    "k_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 256, 110])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_matrix = v(x)\n",
    "v_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_matrix_transpose = k_matrix.permute(0,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 110, 512])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_matrix_transpose.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = torch.matmul(k_matrix_transpose, q_matrix) # [B, Tk, Tq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 110, 110])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.shape#两个维度都分别变成时间维度了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_softmax = o.softmax(1)#注意，1的话是按行扫描，所以是对一列的数据进行softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 110, 110])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o_softmax.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = torch.matmul(v_matrix,o_softmax)#注意，第一个乘数是"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 256, 110])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(r\"../*.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 39, 110])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Conv1d(39, 39,kernel_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = conv1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 39, 110])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_e = torch.randn(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3634])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2 = torch.ones(2,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.9789, 1.9789, 1.9789, 1.9789],\n",
       "         [1.9789, 1.9789, 1.9789, 1.9789],\n",
       "         [1.9789, 1.9789, 1.9789, 1.9789]],\n",
       "\n",
       "        [[1.9789, 1.9789, 1.9789, 1.9789],\n",
       "         [1.9789, 1.9789, 1.9789, 1.9789],\n",
       "         [1.9789, 1.9789, 1.9789, 1.9789]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp2 + bias_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = torch.rand(2,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4441, 0.8244, 0.4262, 0.3668],\n",
       "         [0.4122, 0.8291, 0.5976, 0.9598],\n",
       "         [0.5176, 0.6342, 0.1710, 0.7016]],\n",
       "\n",
       "        [[0.9586, 0.4913, 0.3767, 0.9273],\n",
       "         [0.8638, 0.5397, 0.4672, 0.2715],\n",
       "         [0.1455, 0.7241, 0.7961, 0.5724]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.4441, 1.8244, 1.4262, 1.3668],\n",
       "         [1.4122, 1.8291, 1.5976, 1.9598],\n",
       "         [1.5176, 1.6342, 1.1710, 1.7016]],\n",
       "\n",
       "        [[1.9586, 1.4913, 1.3767, 1.9273],\n",
       "         [1.8638, 1.5397, 1.4672, 1.2715],\n",
       "         [1.1455, 1.7241, 1.7961, 1.5724]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key + torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tanh_key = torch.tanh(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tanh_key.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.rand(4)\n",
    "alpha_t = torch.matmul(tanh_key, v)  # [B, kdim, Tq], kernel_size = 1所以Time是不变的,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9110, 0.9516, 0.8791],\n",
       "        [1.0329, 0.9762, 0.7004]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_t_unseq = alpha_t.unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9110],\n",
       "         [0.9516],\n",
       "         [0.8791]],\n",
       "\n",
       "        [[1.0329],\n",
       "         [0.9762],\n",
       "         [0.7004]]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_t_unseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_alpha_t = alpha_t_unseq.expand(-1,-1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9110, 0.9110, 0.9110, 0.9110],\n",
       "         [0.9516, 0.9516, 0.9516, 0.9516],\n",
       "         [0.8791, 0.8791, 0.8791, 0.8791]],\n",
       "\n",
       "        [[1.0329, 1.0329, 1.0329, 1.0329],\n",
       "         [0.9762, 0.9762, 0.9762, 0.9762],\n",
       "         [0.7004, 0.7004, 0.7004, 0.7004]]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_alpha_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4170, 0.6774, 0.4021, 0.3511],\n",
       "         [0.3904, 0.6800, 0.5353, 0.7442],\n",
       "         [0.4758, 0.5610, 0.1694, 0.6054]],\n",
       "\n",
       "        [[0.7436, 0.4552, 0.3599, 0.7293],\n",
       "         [0.6982, 0.4927, 0.4359, 0.2650],\n",
       "         [0.1445, 0.6195, 0.6619, 0.5171]]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tanh_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = final_alpha_t * tanh_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = torch.sum(output,dim =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1697, 1.7573, 1.0246, 1.5602],\n",
       "        [1.5509, 1.3850, 1.2608, 1.3742]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = torch.sum(output,dim =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_2 = key*key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_left = key_2 * final_alpha_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma_left.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_left_sum = torch.sum(sigma_left, dim = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma_left_sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = torch.sqrt(sigma_left_sum - u*u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1697, 1.7573, 1.0246, 1.5602],\n",
       "        [1.5509, 1.3850, 1.2608, 1.3742]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_acnn = torch.cat([u,sigma],dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_acnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear1 = nn.Linear(8, 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = linear1(C_acnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan, nan],\n",
       "        [nan, nan, nan]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#感觉好像是手动的\n",
    "in_cha = 3\n",
    "out_cha = 3\n",
    "ker_size = 1\n",
    "# weight = nn.Parameter(torch.Tensor(\n",
    "#                 in_channels, out_channels, kernel_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "convs = nn.ModuleList()  # 创建多个一维卷积层\n",
    "N = 3\n",
    "for i in range(N):\n",
    "    convs.append(nn.Conv1d(in_channels = in_cha, out_channels = out_cha, kernel_size = ker_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv1d(3, 3, kernel_size=(1,), stride=(1,))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([self.pool(F.relu(conv(embeddings))).squeeze(-1) for conv in convs], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_beta = torch.tensor([[1,2,3],[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_beta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_feature = torch.rand(2,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4519, 0.6362, 0.3710, 0.5947],\n",
       "         [0.5907, 0.8330, 0.1735, 0.0698],\n",
       "         [0.2487, 0.0451, 0.1134, 0.7435]],\n",
       "\n",
       "        [[0.3901, 0.2463, 0.8774, 0.1199],\n",
       "         [0.9949, 0.4607, 0.1898, 0.0633],\n",
       "         [0.5997, 0.0593, 0.3830, 0.8622]]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#输入就是batch_size, channels, seq_len\n",
    "conv1 = nn.Conv1d(3,5,kernel_size = 1)\n",
    "output1 = conv1(input_feature) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 4])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_output = torch.ones(2,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2_output = torch.full((2,3,4),2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2.]],\n",
       "\n",
       "        [[2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2.]]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[3., 3., 3., 3.],\n",
       "         [3., 3., 3., 3.],\n",
       "         [3., 3., 3., 3.]],\n",
       "\n",
       "        [[3., 3., 3., 3.],\n",
       "         [3., 3., 3., 3.],\n",
       "         [3., 3., 3., 3.]]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv3_output = torch.full((2,3,4),3.0)\n",
    "conv3_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_beta_unsq = my_beta.unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1],\n",
       "         [2],\n",
       "         [3]],\n",
       "\n",
       "        [[4],\n",
       "         [5],\n",
       "         [6]]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_beta_unsq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_beta_unsq_expand = my_beta_unsq.expand(-1,-1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 1, 1],\n",
       "         [2, 2, 2, 2],\n",
       "         [3, 3, 3, 3]],\n",
       "\n",
       "        [[4, 4, 4, 4],\n",
       "         [5, 5, 5, 5],\n",
       "         [6, 6, 6, 6]]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_beta_unsq_expand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cnn_result = [conv1_output,conv2_output,conv3_output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.]],\n",
       " \n",
       "         [[1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.]]]), tensor([[[2., 2., 2., 2.],\n",
       "          [2., 2., 2., 2.],\n",
       "          [2., 2., 2., 2.]],\n",
       " \n",
       "         [[2., 2., 2., 2.],\n",
       "          [2., 2., 2., 2.],\n",
       "          [2., 2., 2., 2.]]]), tensor([[[3., 3., 3., 3.],\n",
       "          [3., 3., 3., 3.],\n",
       "          [3., 3., 3., 3.]],\n",
       " \n",
       "         [[3., 3., 3., 3.],\n",
       "          [3., 3., 3., 3.],\n",
       "          [3., 3., 3., 3.]]])]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cnn_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]]])\n",
      "------------------------------\n",
      "tensor([[[1, 1, 1, 1],\n",
      "         [1, 1, 1, 1],\n",
      "         [1, 1, 1, 1]],\n",
      "\n",
      "        [[4, 4, 4, 4],\n",
      "         [4, 4, 4, 4],\n",
      "         [4, 4, 4, 4]]])\n",
      "------------------------------\n",
      "tensor([[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[4., 4., 4., 4.],\n",
      "         [4., 4., 4., 4.],\n",
      "         [4., 4., 4., 4.]]])\n",
      "------------------------------\n",
      "tensor([[[2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2.]],\n",
      "\n",
      "        [[2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2.]]])\n",
      "------------------------------\n",
      "tensor([[[2, 2, 2, 2],\n",
      "         [2, 2, 2, 2],\n",
      "         [2, 2, 2, 2]],\n",
      "\n",
      "        [[5, 5, 5, 5],\n",
      "         [5, 5, 5, 5],\n",
      "         [5, 5, 5, 5]]])\n",
      "------------------------------\n",
      "tensor([[[ 4.,  4.,  4.,  4.],\n",
      "         [ 4.,  4.,  4.,  4.],\n",
      "         [ 4.,  4.,  4.,  4.]],\n",
      "\n",
      "        [[10., 10., 10., 10.],\n",
      "         [10., 10., 10., 10.],\n",
      "         [10., 10., 10., 10.]]])\n",
      "------------------------------\n",
      "tensor([[[3., 3., 3., 3.],\n",
      "         [3., 3., 3., 3.],\n",
      "         [3., 3., 3., 3.]],\n",
      "\n",
      "        [[3., 3., 3., 3.],\n",
      "         [3., 3., 3., 3.],\n",
      "         [3., 3., 3., 3.]]])\n",
      "------------------------------\n",
      "tensor([[[3, 3, 3, 3],\n",
      "         [3, 3, 3, 3],\n",
      "         [3, 3, 3, 3]],\n",
      "\n",
      "        [[6, 6, 6, 6],\n",
      "         [6, 6, 6, 6],\n",
      "         [6, 6, 6, 6]]])\n",
      "------------------------------\n",
      "tensor([[[ 9.,  9.,  9.,  9.],\n",
      "         [ 9.,  9.,  9.,  9.],\n",
      "         [ 9.,  9.,  9.,  9.]],\n",
      "\n",
      "        [[18., 18., 18., 18.],\n",
      "         [18., 18., 18., 18.],\n",
      "         [18., 18., 18., 18.]]])\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for cnn_result, beta in zip(all_cnn_result,my_beta.T):\n",
    "    print(cnn_result)\n",
    "    print('-'*30)\n",
    "    print(beta.unsqueeze(1).unsqueeze(2).expand(-1,3,4))\n",
    "    print('-'*30)\n",
    "    print(beta.unsqueeze(1).unsqueeze(2).expand(-1,3,4) * cnn_result)\n",
    "    print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    " temp_result = [ conv* (beta.unsqueeze(1).unsqueeze(2).expand(-1,conv.shape[1],conv.shape[2])) for conv,beta in zip(all_cnn_result, my_beta.T)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 4.6667,  4.6667,  4.6667,  4.6667],\n",
       "         [ 4.6667,  4.6667,  4.6667,  4.6667],\n",
       "         [ 4.6667,  4.6667,  4.6667,  4.6667]],\n",
       "\n",
       "        [[10.6667, 10.6667, 10.6667, 10.6667],\n",
       "         [10.6667, 10.6667, 10.6667, 10.6667],\n",
       "         [10.6667, 10.6667, 10.6667, 10.6667]]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sum(temp_result)/len(temp_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-169-36c475e5489a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(temp_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_beta_unsq_2 = my_beta_unsq.unsqueeze(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1]],\n",
       "\n",
       "         [[2]],\n",
       "\n",
       "         [[3]]],\n",
       "\n",
       "\n",
       "        [[[4]],\n",
       "\n",
       "         [[5]],\n",
       "\n",
       "         [[6]]]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_beta_unsq_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 1, 1])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_beta_unsq_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.zeros(2,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size, in_channels, seq_len\n",
    "class ACNN(nn.Module):\n",
    "    def __init__(self,in_channels, out_channels, kernel_size, dilation, seq_len, N):\n",
    "        super(ACNN,self).__init__()\n",
    "        self.W_e = Conv1d(in_channels, out_channels,kernel_size)\n",
    "        self.W_a = Conv1d(in_channels, out_channels,kernel_size)\n",
    "        self.params = nn.ParameterDict({\n",
    "                'b_e': nn.Parameter(torch.randn(1)),\n",
    "                'b_a': nn.Parameter(torch.randn(1)),\n",
    "                'v':nn.Parameter(torch.rand(seq_len))\n",
    "        })\n",
    "        self.W_b_list = nn.ModuleList()\n",
    "        self.N = N\n",
    "        for i in range(N):\n",
    "            self.W_b_list.append(nn.Conv1d(in_channels = in_channels, \n",
    "                                        out_channels = out_channels, \n",
    "                                        kernel_size = kernel_size, bias = True))\n",
    "\n",
    "        # self.b_e = b_e\n",
    "        # self.b_a = b_a\n",
    "        # self.v = v #(seq_len,)\n",
    "        self.linear_combination = nn.Linear(seq_len,N)\n",
    "    def forward(self, x):\n",
    "        e_t = self.W_e(x) + self.params['b_e']#好像Bias = True就可以了\n",
    "        a_t = torch.matmul(self.params['v'], torch.tanh(self.W_a(x) + self.params['b_a']))\n",
    "        a_t = a_t.unsqueeze(2).expand(-1,-1,e_t.shape[2])\n",
    "        u = torch.sum(a_t * e_t, dim = 1)\n",
    "        sigma = torch.sqrt(torch.sum(a_t*(e_t*e_t),dim = 1) - u*u)#batch,seq_len\n",
    "        C_acnn = torch.cat([u,sigma], dim = 1)#batch,seq_len*2\n",
    "        beta = linear_combination(C_acnn)#batch,N 有N个filter\n",
    "        out = sum([ conv(x)* beta.unsqueeze(1).unsqueeze(2).expand(-1,conv.shape[1],conv.shape[2]) for conv in zip(self.W_b_list, beta.T)])/self.N\n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.2209, 5.7971, 2.7860, 4.7599],\n",
       "        [4.7155, 3.9948, 3.5281, 3.9520]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3935)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5539, 0.7566, 0.5373],\n",
       "         [0.4297, 0.3929, 0.9804]],\n",
       "\n",
       "        [[0.9643, 0.3211, 0.6145],\n",
       "         [0.6518, 0.0360, 0.1140]]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_exp = torch.mean(t2,dim = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6159, 0.6010],\n",
       "        [0.6333, 0.2673]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_ = torch.sum(mean_exp,dim = 1).unsqueeze(1).expand(-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5061, 0.4939],\n",
       "        [0.7032, 0.2968]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_exp / sum_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
